@article{b1,
  title={Weapon detection using YOLO V3 for smart surveillance system},
  author={Narejo, Sanam and Pandey, Bishwajeet and Rodriguez, Ciro and Anjum, M Rizwan and others},
  journal={Mathematical Problems in Engineering},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

@article{b2,
  title={Comparing YOLOv3, YOLOv4 and YOLOv5 for autonomous landing spot detection in faulty UAVs},
  author={Nepal, Upesh and Eslamiat, Hossein},
  journal={Sensors},
  volume={22},
  number={2},
  pages={464},
  year={2022},
  publisher={MDPI}
}

@article{b6,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@inproceedings{b7,
  title={Application of Deep Learning for Weapons Detection in Surveillance Videos},
  author={Hashmi, Tufail Sajjad Shah and Haq, Nazeef Ul and Fraz, Muhammad Moazam and Shahzad, Muhammad},
  booktitle={2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{b9,
  title={Responding to the Controversy about YOLOv5},
  author={Nelson, Joseph and Solawetz, Jacob},
  journal={Roboflow Blog [online]},
  volume={2020},
  year={2020}
}

@article{b10,
  title={A forest fire detection system based on ensemble learning},
  author={Xu, Renjie and Lin, Haifeng and Lu, Kangjie and Cao, Lin and Liu, Yunfei},
  journal={Forests},
  volume={12},
  number={2},
  pages={217},
  year={2021},
  publisher={MDPI}
}

@article{b11,
  title={Evolution of Yolo algorithm and Yolov5: The State-of-the-Art object detention algorithm},
  author={Thuan, Do},
  year={2021}
}

@inproceedings{b12,
  title={Rotation Aware Object Detection Model with Applications to Weapons Spotting in Surveillance Videos},
  author={Haq, Nazeef UL and Hashmi, Tufail Sajjad Shah and Fraz, Muhammad Moazam and Shahzad, Muhammad},
  booktitle={2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{b13,
  title={Orientation Aware Weapons Detection In Visual Data: A Benchmark Dataset},
  author={Haq, Nazeef Ul and Fraz, Muhammad Moazam and Hashmi, Tufail Sajjad Shah and Shahzad, Muhammad},
  journal={arXiv preprint arXiv:2112.02221},
  year={2021}
}

@article{b14,
  title={A forest fire detection system based on ensemble learning},
  author={Xu, Renjie and Lin, Haifeng and Lu, Kangjie and Cao, Lin and Liu, Yunfei},
  journal={Forests},
  volume={12},
  number={2},
  pages={217},
  year={2021},
  publisher={MDPI}
}

@article{b15,
  title={An In-ad contents-based viewability prediction framework using Artificial Intelligence for Web Ads},
  author={Asad, Muhammad and Halim, Zahid and Waqas, Muhammad and Tu, Shanshan},
  journal={Artificial Intelligence Review},
  volume={54},
  number={7},
  pages={5095--5125},
  year={2021},
  publisher={Springer}
}

@article{b16,
  title={iVision HHID: Handwritten hyperspectral images dataset for benchmarking hyperspectral imaging-based document forensic analysis},
  author={Islam, Ammad Ul and Khan, Muhammad Jaleed and Asad, Muhammad and Khan, Haris Ahmad and Khurshid, Khurram},
  journal={Data in Brief},
  volume={41},
  pages={107964},
  year={2022},
  publisher={Elsevier}
}

@article{b8,
  title={Significance of Machine Learning for Detection of Malicious Websites on an Unbalanced Dataset},
  author={Ul Hassan, Ietezaz and Ali, Raja Hashim and Ul Abideen, Zain and Khan, Talha Ali and Kouatly, Rand},
  journal={Digital},
  volume={2},
  number={4},
  pages={501--519},
  year={2022},
  publisher={MDPI}
}

@inproceedings{b17,
  title={Breast Cancer Classification and Proof of Key Artificial Neural Network Terminologies},
  author={Ali, Nisar and Ansari, Shahab and Halim, Zahid and Ali, Raja Hashim and Khan, Muhammad Faizan and Khan, Mohsin},
  booktitle={2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@misc{b3, title={Ultralytics/yolov5: Yolov5 in PyTorch \> ONNX \> CoreML \> TFLite}, url={https://github.com/ultralytics/yolov5}, journal={GitHub}} 

@misc{b4, title={What is Yolov5? A guide for beginners.}, url={https://blog.roboflow.com/yolov5-improvements-and-evaluation}, journal={Roboflow Blog}, publisher={Roboflow Blog}, author={Solawetz, Jacob}, year={2022}, month={Nov}} 

@misc{b5, title={Object detection algorithm-YOLO V5 architecture}, url={https://medium.com/analytics-vidhya/object-detection-algorithm-yolo-v5-architecture-89e0a35472ef}, journal={Medium}, publisher={Analytics Vidhya}, author={Gutta, Surya}, year={2021}, month={Aug}} 


@inproceedings{b18,
  title={Breast Cancer Classification and Proof of Key Artificial Neural Network Terminologies},
  author={Ali, Nisar and Ansari, Shahab and Halim, Zahid and Ali, Raja Hashim and Khan, Muhammad Faizan and Khan, Mohsin},
  booktitle={2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

% This file was created with JabRef 2.5.
% Encoding: Cp1252

@inproceedings{Hkansson2013PortalOR,
  title={Portal of Research Methods and Methodologies for Research Projects and Degree Projects},
  author={Anne H{\aa}kansson},
  year={2013}
}


@article{weighted_srgan_2021,
  title = {Weighted {SRGAN} and {Reconstruction} {Loss} {Analysis} for {Accurate} {Image} {Super} {Resolution}},
  volume = {1903},
  url = {https://dx.doi.org/10.1088/1742-6596/1903/1/012050},
  doi = {10.1088/1742-6596/1903/1/012050},
  abstract = {Super resolution (SR) image generation is to generate a high-resolution image from a given low-resolution image, which can be used in numerous vision tasks, such as small object detection and specific image processing. Generative adversarial network for super resolution (SRGAN) is the mainstream framework in SR task, which utilizes two reconstruction losses, including MSE loss and VGG loss. However, the influence of these losses on model learning is not examined. In this paper, the importance of MSE and VGG losses is analyzed. The loss function of traditional SRGAN is improved, and the weights of MSE and VGG losses are set manually. The weights range from 0 to 1, and the sampling interval is 0.1. Furthermore, a learnable parameter to dynamically adjust the two weights is proposed. Experiments on the datasets, including Set5, Set14, BAS100, and Urban100, show that our method is capable of generating much better images than SRGAN, with higher values of PSNR and SSIM. It is found that the MSE loss makes a greater contribution to learning the discriminative model and the VGG loss plays a supplementary role. Our WSRGAN can apply to most SRGAN-based methods to improve their accuracy.},
  number = {1},
  journal = {Journal of Physics: Conference Series},
  author = {Cao, Hangpu and Mi, Sicheng},
  month = apr,
  year = {2021},
  note = {Publisher: IOP Publishing},
  pages = {012050},
}

@article{video_super_resolution_survey_2020,
  author       = {Hongying Liu and
                  Zhubo Ruan and
                  Peng Zhao and
                  Fanhua Shang and
                  Linlin Yang and
                  Yuanyuan Liu},
  title        = {Video Super Resolution Based on Deep Learning: {A} comprehensive survey},
  journal      = {CoRR},
  volume       = {abs/2007.12928},
  year         = {2020},
  url          = {https://arxiv.org/abs/2007.12928},
  eprinttype    = {arXiv},
  eprint       = {2007.12928},
  timestamp    = {Thu, 30 Jul 2020 08:46:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2007-12928.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{srgan_2016,
  author       = {Christian Ledig and
                  Lucas Theis and
                  Ferenc Huszar and
                  Jose Caballero and
                  Andrew P. Aitken and
                  Alykhan Tejani and
                  Johannes Totz and
                  Zehan Wang and
                  Wenzhe Shi},
  title        = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial
                  Network},
  journal      = {CoRR},
  volume       = {abs/1609.04802},
  year         = {2016},
  url          = {http://arxiv.org/abs/1609.04802},
  eprinttype    = {arXiv},
  eprint       = {1609.04802},
  timestamp    = {Mon, 13 Aug 2018 16:48:38 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LedigTHCATTWS16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{esrgan_2018,
  author       = {Xintao Wang and
                  Ke Yu and
                  Shixiang Wu and
                  Jinjin Gu and
                  Yihao Liu and
                  Chao Dong and
                  Chen Change Loy and
                  Yu Qiao and
                  Xiaoou Tang},
  title        = {{ESRGAN:} Enhanced Super-Resolution Generative Adversarial Networks},
  journal      = {CoRR},
  volume       = {abs/1809.00219},
  year         = {2018},
  url          = {http://arxiv.org/abs/1809.00219},
  eprinttype    = {arXiv},
  eprint       = {1809.00219},
  timestamp    = {Tue, 09 Aug 2022 10:54:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1809-00219.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{frvsr_2018,
  author       = {Mehdi S. M. Sajjadi and
                  Raviteja Vemulapalli and
                  Matthew Brown},
  title        = {Frame-Recurrent Video Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1801.04590},
  year         = {2018},
  url          = {http://arxiv.org/abs/1801.04590},
  eprinttype    = {arXiv},
  eprint       = {1801.04590},
  timestamp    = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1801-04590.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{iSeeBetter_2020,
  author       = {Aman Chadha and
                  John Britto and
                  M. Mani Roja},
  title        = {iSeeBetter: Spatio-temporal video super-resolution using recurrent
                  generative back-projection networks},
  journal      = {CoRR},
  volume       = {abs/2006.11161},
  year         = {2020},
  url          = {https://arxiv.org/abs/2006.11161},
  eprinttype    = {arXiv},
  eprint       = {2006.11161},
  timestamp    = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2006-11161.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@unpublished{iSeeBetter_milestone,
  author = {Aman Chadha},
  note   = {System Performance and Architecture, Apple Inc., CS230: Deep Learning, Project Milestone},
  title  = {iSeeBetter: A Novel Approach to Video Super-Resolution using Adaptive Frame Recurrence and Generative Adversarial Networks},
  year   = {2019}
}

@book{brownlee2019generative,
  title={Generative Adversarial Networks with Python: Deep Learning Generative Models for Image Synthesis and Image Translation},
  author={Brownlee, J.},
  url={https://books.google.pl/books?id=YBimDwAAQBAJ},
  year={2019},
  publisher={Machine Learning Mastery}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{delve_deep_into_rectifiers_2015,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
                  ImageNet Classification},
  journal      = {CoRR},
  volume       = {abs/1502.01852},
  year         = {2015},
  url          = {http://arxiv.org/abs/1502.01852},
  eprinttype    = {arXiv},
  eprint       = {1502.01852},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/HeZR015.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{sub_pixel_cnn_2016,
  author       = {Wenzhe Shi and
                  Jose Caballero and
                  Ferenc Husz{\'{a}}r and
                  Johannes Totz and
                  Andrew P. Aitken and
                  Rob Bishop and
                  Daniel Rueckert and
                  Zehan Wang},
  title        = {Real-Time Single Image and Video Super-Resolution Using an Efficient
                  Sub-Pixel Convolutional Neural Network},
  journal      = {CoRR},
  volume       = {abs/1609.05158},
  year         = {2016},
  url          = {http://arxiv.org/abs/1609.05158},
  eprinttype    = {arXiv},
  eprint       = {1609.05158},
  timestamp    = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ShiCHTABRW16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{vgg_very_deep_cnn_2014,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@INPROCEEDINGS{fast_video_super_reso_ann_2012,
  author={Ming-Hui Cheng and Nai-Wei Lin and Kao-Shing Hwang and Jyh-Horng Jeng},
  booktitle={2012 8th International Symposium on Communication Systems, Networks \& Digital Signal Processing (CSNDSP)},
  title={Fast video super-resolution using artificial neural networks},
  year={2012},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/CSNDSP.2012.6292646}
}


@ARTICLE{universal_image_quality_index_2002,
  author={Zhou Wang and Bovik, A.C.},
  journal={IEEE Signal Processing Letters},
  title={A universal image quality index},
  year={2002},
  volume={9},
  number={3},
  pages={81-84},
  doi={10.1109/97.995823}
}

@article{sr_with_deep_conv_sufficient_stats_2015,
  title={Super-resolution with deep convolutional sufficient statistics},
  author={Bruna, Joan and Sprechmann, Pablo and LeCun, Yann},
  journal={arXiv preprint arXiv:1511.05666},
  year={2015}
}

@article{texture_synth_cnn_2015,
  title={Texture synthesis using convolutional neural networks},
  author={Gatys, Leon and Ecker, Alexander S and Bethge, Matthias},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@ARTICLE{image_upsampling_total_variation_regularization_2005,
  author={Aly, H.A. and Dubois, E.},
  journal={IEEE Transactions on Image Processing},
  title={Image up-sampling using total-variation regularization with a new observation model},
  year={2005},
  volume={14},
  number={10},
  pages={1647-1659},
  doi={10.1109/TIP.2005.851684}
}

@article{deep_learning_image_sr_2020,
  title={Deep learning for image super-resolution: A survey},
  author={Wang, Zhihao and Chen, Jian and Hoi, Steven CH},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={10},
  pages={3365--3387},
  year={2020},
  publisher={IEEE}
}

@article{vimeo90k_2019,
  title={Video Enhancement with Task-Oriented Flow},
  author={Xue, Tianfan and Chen, Baian and Wu, Jiajun and Wei, Donglai and Freeman, William T},
  journal={International Journal of Computer Vision (IJCV)},
  volume={127},
  number={8},
  pages={1106--1125},
  year={2019},
  publisher={Springer}
}

@article{set5_2012,
  title={Low-complexity single-image super-resolution based on nonnegative neighbor embedding},
  author={Bevilacqua, Marco and Roumy, Aline and Guillemot, Christine and Alberi-Morel, Marie Line},
  year={2012},
  publisher={BMVA press}
}


@inproceedings{Set14_2012,
	abstract = {This paper deals with the single image scale-up problem using sparse-representation modeling. The goal is to recover an original image from its blurred and down-scaled noisy version. Since this problem is highly ill-posed, a prior is needed in order to regularize it. The literature offers various ways to address this problem, ranging from simple linear space-invariant interpolation schemes (e.g., bicubic interpolation), to spatially-adaptive and non-linear filters of various sorts. We embark from a recently-proposed successful algorithm by Yang et. al. [1,2], and similarly assume a local Sparse-Land model on image patches, serving as regularization. Several important modifications to the above-mentioned solution are introduced, and are shown to lead to improved results. These modifications include a major simplification of the overall process both in terms of the computational complexity and the algorithm architecture, using a different training approach for the dictionary-pair, and introducing the ability to operate without a training-set by boot-strapping the scale-up task from the given low-resolution image. We demonstrate the results on true images, showing both visual and PSNR improvements.},
	address = {Berlin, Heidelberg},
	author = {Zeyde, Roman and Elad, Michael and Protter, Matan},
	booktitle = {Curves and Surfaces},
	editor = {Boissonnat, Jean-Daniel and Chenin, Patrick and Cohen, Albert and Gout, Christian and Lyche, Tom and Mazure, Marie-Laurence and Schumaker, Larry},
	isbn = {978-3-642-27413-8},
	pages = {711--730},
	publisher = {Springer Berlin Heidelberg},
	title = {On Single Image Scale-Up Using Sparse-Representations},
	year = {2012}
}


@inproceedings{urban100_2015,
    title={Single Image Super-Resolution From Transformed Self-Exemplars},
    Author = {Huang, Jia-Bin and Singh, Abhishek and Ahuja, Narendra},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={5197--5206},
    Year = {2015}
}

@INPROCEEDINGS{BSD100_2001,
  author={Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
  title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},
  year={2001},
  volume={2},
  number={},
  pages={416-423 vol.2},
  doi={10.1109/ICCV.2001.937655}
}


@misc{guide_to_sr_2020,
  author       = {Sagar Vinodababu},
  howpublished = {\url{https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution}},
  title        = {Tutorial to Super-Resolution},
  year         = {2020}
}

@InProceedings{sr_ill_posed_2021,
    author    = {Jo, Younghyun and Oh, Seoung Wug and Vajda, Peter and Kim, Seon Joo},
    title     = {Tackling the Ill-Posedness of Super-Resolution Through Adaptive Target Generation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {16236-16245}
}

@article{Hitchhiker_guide_super_res_2023,
	doi = {10.1109/tpami.2023.3243794},
	url = {https://doi.org/10.1109%2Ftpami.2023.3243794},
	year = 2023,
	month = {aug},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {45},
	number = {8},
	pages = {9862--9882},
	author = {Brian B. Moser and Federico Raue and Stanislav Frolov and Sebastian Palacio and Jörn Hees and Andreas Dengel},
	title = {Hitchhiker{\textquotesingle}s Guide to Super-Resolution: Introduction and Recent Advances},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@ARTICLE{sr_technical_overview_2003,
  author={Sung Cheol Park and Min Kyu Park and Moon Gi Kang},
  journal={IEEE Signal Processing Magazine},
  title={Super-resolution image reconstruction: a technical overview},
  year={2003},
  volume={20},
  number={3},
  pages={21-36},
  doi={10.1109/MSP.2003.1203207}
}

@article{bilinear_interpolation_2013,
author = {Mastyło, Mieczysław},
year = {2013},
month = {07},
pages = {185–207},
title = {Bilinear interpolation theorems and applications},
volume = {265},
journal = {Journal of Functional Analysis},
doi = {10.1016/j.jfa.2013.05.001}
}

@article{bicubic_interpolation_2001,
title = {Gary D. Knott, Interpolating Cubic Splines},
journal = {Journal of Approximation Theory},
volume = {112},
number = {2},
pages = {319-321},
year = {2001},
issn = {0021-9045},
doi = {https://doi.org/10.1006/jath.2001.3603},
url = {https://www.sciencedirect.com/science/article/pii/S0021904501936032},
author = {Gerhard Opfer}
}

@inproceedings{nearest_neighbor_methods_2015,
  title={Lectures on the Nearest Neighbor Method},
  author={Grard Biau and Luc Devroye},
  year={2015}
}

@ARTICLE{extraction_frames_video_sequences_1996,
  author={Schultz, R.R. and Stevenson, R.L.},
  journal={IEEE Transactions on Image Processing},
  title={Extraction of high-resolution frames from video sequences},
  year={1996},
  volume={5},
  number={6},
  pages={996-1011},
  doi={10.1109/83.503915}
}

@ARTICLE{bayesian_vsr_2014,
  author={Liu, Ce and Sun, Deqing},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={On Bayesian Adaptive Video Super Resolution},
  year={2014},
  volume={36},
  number={2},
  pages={346-360},
  doi={10.1109/TPAMI.2013.127}
}

@article{nonlinear_total_variation_noise_removal_1992,
title = {Nonlinear total variation based noise removal algorithms},
journal = {Physica D: Nonlinear Phenomena},
volume = {60},
number = {1},
pages = {259-268},
year = {1992},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(92)90242-F},
url = {https://www.sciencedirect.com/science/article/pii/016727899290242F},
author = {Leonid I. Rudin and Stanley Osher and Emad Fatemi},
abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t → ∞ the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.}
}

@INPROCEEDINGS{SRGAN_with_tv_loss_face_2020,
  author={Nguyen-Truong, Hai and Nguyen, Khoa N. A. and Cao, San},
  booktitle={2020 7th NAFOSTED Conference on Information and Computer Science (NICS)},
  title={SRGAN with Total Variation Loss in Face Super-Resolution},
  year={2020},
  volume={},
  number={},
  pages={292-297},
  doi={10.1109/NICS51282.2020.9335836}
}

@article{Perceptual_Losses_for_Real_Time_Style_Transfer_and_Super_Resolution_2016,
  author       = {Justin Johnson and
                  Alexandre Alahi and
                  Li Fei{-}Fei},
  title        = {Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1603.08155},
  year         = {2016},
  url          = {http://arxiv.org/abs/1603.08155},
  eprinttype    = {arXiv},
  eprint       = {1603.08155},
  timestamp    = {Wed, 15 Sep 2021 14:13:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/JohnsonAL16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{GANs_Python_2019,
  author         = {Jason Brownlee},
  editor         = {},
  publisher      = {Machine Learning Mastery},
  title          = {Generative Adversarial Networks with Python: Deep Learning Generative Models for Image Synthesis and Image Translation},
  year           = {2019}
}

@article{GANs_perc_loss_vsr_2018,
  author       = {Alice Lucas and
                  Santiago Lopez Tapia and
                  Rafael Molina and
                  Aggelos K. Katsaggelos},
  title        = {Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1806.05764},
  year         = {2018},
  url          = {http://arxiv.org/abs/1806.05764},
  eprinttype    = {arXiv},
  eprint       = {1806.05764},
  timestamp    = {Tue, 15 Oct 2019 17:25:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1806-05764.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{tecogan_2018,
  author       = {Mengyu Chu and
                  You Xie and
                  Laura Leal{-}Taix{\'{e}} and
                  Nils Thuerey},
  title        = {Temporally Coherent GANs for Video Super-Resolution (TecoGAN)},
  journal      = {CoRR},
  volume       = {abs/1811.09393},
  year         = {2018},
  url          = {http://arxiv.org/abs/1811.09393},
  eprinttype    = {arXiv},
  eprint       = {1811.09393},
  timestamp    = {Thu, 14 Oct 2021 09:14:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1811-09393.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{vid4_2014,
  author={Liu, Ce and Sun, Deqing},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={On Bayesian Adaptive Video Super Resolution},
  year={2014},
  volume={36},
  number={2},
  pages={346-360},
  doi={10.1109/TPAMI.2013.127}
}

@article{Real_Time_Video_Super_Resolution_with_Spatio_Temporal_Networks_and_Motion_Compensation_2016,
  author       = {Jose Caballero and
                  Christian Ledig and
                  Andrew P. Aitken and
                  Alejandro Acosta and
                  Johannes Totz and
                  Zehan Wang and
                  Wenzhe Shi},
  title        = {Real-Time Video Super-Resolution with Spatio-Temporal Networks and
                  Motion Compensation},
  journal      = {CoRR},
  volume       = {abs/1611.05250},
  year         = {2016},
  url          = {http://arxiv.org/abs/1611.05250},
  eprinttype    = {arXiv},
  eprint       = {1611.05250},
  timestamp    = {Mon, 13 Aug 2018 16:46:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/CaballeroLAATWS16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{HandsOn_GANs_2019,
  author         = {John Hany and
                    Greg Walters},
  editor         = {},
  publisher      = {Packt Publishing Ltd},
  title          = {Hands-On Generative Adversarial Networks with PyTorch 1.x: Implement next-generation neural networks to build powerful GAN models using Python},
  year           = {2019}
}

@article{single_vsr_gan_pseudo_inverse_2019,
  author       = {Santiago L{\'{o}}pez{-}Tapia and
                  Alice Lucas and
                  Rafael Molina and
                  Aggelos K. Katsaggelos},
  title        = {A Single Video Super-Resolution {GAN} for Multiple Downsampling Operators
                  based on Pseudo-Inverse Image Formation Models},
  journal      = {CoRR},
  volume       = {abs/1907.01399},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.01399},
  eprinttype    = {arXiv},
  eprint       = {1907.01399},
  timestamp    = {Tue, 15 Oct 2019 17:25:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-01399.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{checkerboard_2020,
  title={Checkerboard-artifact-free image-enhancement network considering local and global features},
  author={Kinoshita, Yuma and Kiya, Hitoshi},
  booktitle={2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={1139--1144},
  year={2020},
  organization={IEEE}
}

@article{ssim_2004,
author = {Wang, Zhou and Bovik, Alan and Sheikh, Hamid and Simoncelli, Eero},
year = {2004},
month = {05},
pages = {600 - 612},
title = {Image Quality Assessment: From Error Visibility to Structural Similarity},
volume = {13},
journal = {Image Processing, IEEE Transactions on},
doi = {10.1109/TIP.2003.819861}
}

@article{sisr_survey_2022,
  title={Single Image Super-Resolution Methods: A Survey},
  author={Maral, Bahattin Can},
  journal={arXiv preprint arXiv:2202.11763},
  year={2022}
}

@article{misr_remote_2020,
	abstract = {Convolutional Neural Networks (CNNs) consistently proved state-of-the-art results in image Super-resolution (SR), representing an exceptional opportunity for the remote sensing field to extract further information and knowledge from captured data. However, most of the works published in the literature focused on the Single-image Super-resolution problem so far. At present, satellite-based remote sensing platforms offer huge data availability with high temporal resolution and low spatial resolution. In this context, the presented research proposes a novel residual attention model (RAMS) that efficiently tackles the Multi-image Super-resolution task, simultaneously exploiting spatial and temporal correlations to combine multiple images. We introduce the mechanism of visual feature attention with 3D convolutions in order to obtain an aware data fusion and information extraction of the multiple low-resolution images, transcending limitations of the local region of convolutional operations. Moreover, having multiple inputs with the same scene, our representation learning network makes extensive use of nestled residual connections to let flow redundant low-frequency signals and focus the computation on more important high-frequency components. Extensive experimentation and evaluations against other available solutions, either for Single or Multi-image Super-resolution, demonstrated that the proposed deep learning-based solution can be considered state-of-the-art for Multi-image Super-resolution for remote sensing applications.},
	article-number = {2207},
	author = {Salvetti, Francesco and Mazzia, Vittorio and Khaliq, Aleem and Chiaberge, Marcello},
	doi = {10.3390/rs12142207},
	issn = {2072-4292},
	journal = {Remote Sensing},
	number = {14},
	title = {Multi-Image Super Resolution of Remotely Sensed Images Using Residual Attention Deep Neural Networks},
	url = {https://www.mdpi.com/2072-4292/12/14/2207},
	volume = {12},
	year = {2020},
	bdsk-url-1 = {https://www.mdpi.com/2072-4292/12/14/2207},
	bdsk-url-2 = {https://doi.org/10.3390/rs12142207}}

  @article{imagenet_2015,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{alexnet_2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{inception_2015,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{resnet_2016,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{cnn_intro_2018,
  author       = {Keiron O'Shea and
                  Ryan Nash},
  title        = {An Introduction to Convolutional Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1511.08458},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.08458},
  eprinttype    = {arXiv},
  eprint       = {1511.08458},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Harris1964DiffractionAR,
  title={Diffraction and Resolving Power},
  author={James L. Harris},
  journal={Journal of the Optical Society of America},
  year={1964},
  volume={54},
  pages={931-936},
  url={https://api.semanticscholar.org/CorpusID:122099151}
}

@inproceedings{Tsai1984MultiframeIR,
  title={Multiframe image restoration and registration},
  author={Roger Y. Tsai and Thomas S. Huang},
  year={1984},
  url={https://api.semanticscholar.org/CorpusID:59796060}
}

@article{sr_comprehensive_survey_2014,
author = {Nasrollahi, Kamal and Moeslund, Thomas},
year = {2014},
month = {08},
pages = {1423-1468},
title = {Super-resolution: A comprehensive survey},
volume = {25},
journal = {Machine Vision and Applications},
doi = {10.1007/s00138-014-0623-4}
}

@INPROCEEDINGS{Multi_frame_sr_2019,
  author={Seema, R and Bailey, Kiran},
  booktitle={2019 2nd International Conference on Signal Processing and Communication (ICSPC)},
  title={Multi-frame Image Super-Resolution by Interpolation and Iterative Backward Projection},
  year={2019},
  volume={},
  number={},
  pages={36-40},
  doi={10.1109/ICSPC46172.2019.8976500}}

@ARTICLE{reconstruction_methods_2004,
  author={Zhouchen Lin and Heung-Yeung Shum},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Fundamental limits of reconstruction-based superresolution algorithms under local translation},
  year={2004},
  volume={26},
  number={1},
  pages={83-97},
  doi={10.1109/TPAMI.2004.1261081}}

@phdthesis{deep_cna_2020,
author = {Stern, Maike},
year = {2020},
month = {01},
pages = {},
title = {Development of a Fully-Convolutional-Network Architecture for the Detection of Defective LED Chips in Photoluminescence Images}
}

@inproceedings{tao2017detail,
  title={Detail-revealing deep video super-resolution},
  author={Tao, Xin and Gao, Hongyun and Liao, Renjie and Wang, Jue and Jia, Jiaya},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4472--4480},
  year={2017}
}

@INPROCEEDINGS{Robust_VSR_2017,
  author={Liu, Ding and Wang, Zhaowen and Fan, Yuchen and Liu, Xianming and Wang, Zhangyang and Chang, Shiyu and Huang, Thomas},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
  title={Robust Video Super-Resolution with Learned Temporal Dynamics},
  year={2017},
  volume={},
  number={},
  pages={2526-2534},
  doi={10.1109/ICCV.2017.274}}

@article{gans_overview_2018,
  title={Generative adversarial networks: An overview},
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A},
  journal={IEEE signal processing magazine},
  volume={35},
  number={1},
  pages={53--65},
  year={2018},
  publisher={IEEE}
}

@article{image_sr_dcnn_2015,
  author       = {Chao Dong and
                  Chen Change Loy and
                  Kaiming He and
                  Xiaoou Tang},
  title        = {Image Super-Resolution Using Deep Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1501.00092},
  year         = {2015},
  url          = {http://arxiv.org/abs/1501.00092},
  eprinttype    = {arXiv},
  eprint       = {1501.00092},
  timestamp    = {Mon, 13 Aug 2018 16:46:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DongLHT15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{accurate_image_sr_kim_2015,
  author       = {Jiwon Kim and
                  Jung Kwon Lee and
                  Kyoung Mu Lee},
  title        = {Accurate Image Super-Resolution Using Very Deep Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1511.04587},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.04587},
  eprinttype    = {arXiv},
  eprint       = {1511.04587},
  timestamp    = {Mon, 13 Aug 2018 16:46:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KimLL15b.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Tang_Accelerating_sr_cnn_2016,
  author       = {Chao Dong and
                  Chen Change Loy and
                  Xiaoou Tang},
  title        = {Accelerating the Super-Resolution Convolutional Neural Network},
  journal      = {CoRR},
  volume       = {abs/1608.00367},
  year         = {2016},
  url          = {http://arxiv.org/abs/1608.00367},
  eprinttype    = {arXiv},
  eprint       = {1608.00367},
  timestamp    = {Mon, 13 Aug 2018 16:47:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DongLT16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{deeply_recursive_sr_2015,
  author       = {Jiwon Kim and
                  Jung Kwon Lee and
                  Kyoung Mu Lee},
  title        = {Deeply-Recursive Convolutional Network for Image Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1511.04491},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.04491},
  eprinttype    = {arXiv},
  eprint       = {1511.04491},
  timestamp    = {Mon, 13 Aug 2018 16:48:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KimLL15a.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Shi_real_time_vsr_sub_pix_2016,
  author       = {Wenzhe Shi and
                  Jose Caballero and
                  Ferenc Husz{\'{a}}r and
                  Johannes Totz and
                  Andrew P. Aitken and
                  Rob Bishop and
                  Daniel Rueckert and
                  Zehan Wang},
  title        = {Real-Time Single Image and Video Super-Resolution Using an Efficient
                  Sub-Pixel Convolutional Neural Network},
  journal      = {CoRR},
  volume       = {abs/1609.05158},
  year         = {2016},
  url          = {http://arxiv.org/abs/1609.05158},
  eprinttype    = {arXiv},
  eprint       = {1609.05158},
  timestamp    = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ShiCHTABRW16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{resid_dende_net_2018,
  author       = {Yulun Zhang and
                  Yapeng Tian and
                  Yu Kong and
                  Bineng Zhong and
                  Yun Fu},
  title        = {Residual Dense Network for Image Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1802.08797},
  year         = {2018},
  url          = {http://arxiv.org/abs/1802.08797},
  eprinttype    = {arXiv},
  eprint       = {1802.08797},
  timestamp    = {Mon, 13 Aug 2018 16:46:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1802-08797.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{2x_sr_hardware_2018,
  author={Kim, Yongwoo and Choi, Jae-Seok and Kim, Munchurl},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs},
  title={2X Super-Resolution Hardware Using Edge-Orientation-Based Linear Mapping for Real-Time 4K UHD 60 fps Video Applications},
  year={2018},
  volume={65},
  number={9},
  pages={1274-1278},
  doi={10.1109/TCSII.2018.2799577}}

@INPROCEEDINGS{fpga_2019,
  author={Wei, Yuzhuo and Chen, Li and Xie, Rong and Song, Li and Zhang, Xiaoyun and Gao, Zhiyong},
  booktitle={2019 IEEE Visual Communications and Image Processing (VCIP)},
  title={FPGA Based Video Transcoding System with 2K-4K Super-Resolution Conversion},
  year={2019},
  volume={},
  number={},
  pages={1-2},
  doi={10.1109/VCIP47243.2019.8966063}}

  @INPROCEEDINGS{tomography_cnn_2017,
  author={Yu, Haichao and Liu, Ding and Shi, Honghui and Yu, Hanchao and Wang, Zhangyang and Wang, Xinchao and Cross, Brent and Bramler, Matthew and Huang, Thomas S.},
  booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
  title={Computed tomography super-resolution using convolutional neural networks},
  year={2017},
  volume={},
  number={},
  pages={3944-3948},
  doi={10.1109/ICIP.2017.8297022}}

  @inproceedings{medical_image_2020,
  title={Efficient and phase-aware video super-resolution for cardiac MRI},
  author={Lin, Jhih-Yuan and Chang, Yu-Cheng and Hsu, Winston H},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2020: 23rd International Conference, Lima, Peru, October 4--8, 2020, Proceedings, Part IV 23},
  pages={66--76},
  year={2020},
  organization={Springer}
}

@ARTICLE{video_satellite_sr_2017,
  author={Luo, Yimin and Zhou, Liguo and Wang, Shu and Wang, Zhongyuan},
  journal={IEEE Geoscience and Remote Sensing Letters},
  title={Video Satellite Imagery Super Resolution via Convolutional Neural Networks},
  year={2017},
  volume={14},
  number={12},
  pages={2398-2402},
  doi={10.1109/LGRS.2017.2766204}}


@Article{sr_jilin_cnn_2018,
AUTHOR = {Xiao, Aoran and Wang, Zhongyuan and Wang, Lei and Ren, Yexian},
TITLE = {Super-Resolution for “Jilin-1” Satellite Video Imagery via a Convolutional Network},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1194},
URL = {https://www.mdpi.com/1424-8220/18/4/1194},
PubMedID = {29652838},
ISSN = {1424-8220},
ABSTRACT = {Super-resolution for satellite video attaches much significance to earth observation accuracy, and the special imaging and transmission conditions on the video satellite pose great challenges to this task. The existing deep convolutional neural-network-based methods require pre-processing or post-processing to be adapted to a high-resolution size or pixel format, leading to reduced performance and extra complexity. To this end, this paper proposes a five-layer end-to-end network structure without any pre-processing and post-processing, but imposes a reshape or deconvolution layer at the end of the network to retain the distribution of ground objects within the image. Meanwhile, we formulate a joint loss function by combining the output and high-dimensional features of a non-linear mapping network to precisely learn the desirable mapping relationship between low-resolution images and their high-resolution counterparts. Also, we use satellite video data itself as a training set, which favors consistency between training and testing images and promotes the method’s practicality. Experimental results on “Jilin-1” satellite video imagery show that this method demonstrates a superior performance in terms of both visual effects and measure metrics over competing methods.},
DOI = {10.3390/s18041194}
}

@ARTICLE{stallite_vsr_neighb_2020,
  author={Liu, Huan and Gu, Yanfeng and Wang, Tengfei and Li, Shengyang},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  title={Satellite Video Super-Resolution Based on Adaptively Spatiotemporal Neighbors and Nonlocal Similarity Regularization},
  year={2020},
  volume={58},
  number={12},
  pages={8372-8383},
  doi={10.1109/TGRS.2020.2987400}}

  @inproceedings{multiview_vsr_extract_2016,
author = {Li, Yawei and Li, Xiaofeng and Fu, Zhizhong and Zhong, Wenli},
year = {2016},
month = {10},
pages = {446-450},
title = {Multiview Video Super-Resolution via Information Extraction and Merging},
doi = {10.1145/2964284.2967260}
}

@inproceedings{3d_appearance_sr_dl_2019,
  title={3D appearance super-resolution with deep learning},
  author={Li, Yawei and Tsiminaki, Vagia and Timofte, Radu and Pollefeys, Marc and Gool, Luc Van},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9671--9680},
  year={2019}
}

@INPROCEEDINGS{license_place_rec_2018,
  author={Lee, Younkwan and Yun, JaeWoong and Hong, Yoojin and Lee, Juhyun and Jeon, Moongu},
  booktitle={2018 IEEE International Conference on Consumer Electronics - Asia (ICCE-Asia)},
  title={Accurate License Plate Recognition and Super-Resolution Using a Generative Adversarial Networks on Traffic Surveillance Video},
  year={2018},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICCE-ASIA.2018.8552121}}

@article{guo_motion_blur_vsr_2020,
title = {Towards efficient motion-blurred public security video super-resolution based on back-projection networks},
journal = {Journal of Network and Computer Applications},
volume = {166},
pages = {102691},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102691},
url = {https://www.sciencedirect.com/science/article/pii/S108480452030165X},
author = {Kehua Guo and Haifu Guo and Sheng Ren and Jian Zhang and Xi Li},
keywords = {Public security, Video super-resolution, Motion blur, Deep learning, Artificial intelligence},
abstract = {In public security, video super-resolution has been an important technology for assisting users in effectively locating potential safety hazards. However, the video collected from video monitoring equipment is usually polluted by motion blur and noise, which results in low video quality after reconstruction. In this paper, we propose a super-resolution reconstruction model for motion-blurred video to reconstruct corresponding high-resolution video from motion-blurred low-resolution video. First, a single-frame image super-resolution model is designed based on the improved deep back-projection network, which primarily includes the design of a recursive method. Second, a multi-frame image super-resolution model is designed based on an optical motion algorithm for motion estimation and motion compensation of video frame sequences. Finally, according to the motion-blurred low-resolution video pollution condition, the de-blurring algorithm and multi-frame image super-resolution are combined to propose a super-resolution reconstruction model for motion-blurred video. Experiments show that the proposed motion-blurred video super-resolution model is superior to other contrasted algorithms in clear video and motion-blurred video reconstruction and has a better reconstruction effect and higher practical value.}
}

@inproceedings{kupyn2018deblurgan,
  title={Deblurgan: Blind motion deblurring using conditional adversarial networks},
  author={Kupyn, Orest and Budzan, Volodymyr and Mykhailych, Mykola and Mishkin, Dmytro and Matas, Ji{\v{r}}{\'\i}},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8183--8192},
  year={2018}
}

@article{ZHANG20181,
title = {Spatio-temporal super-resolution for multi-videos based on belief propagation},
journal = {Signal Processing: Image Communication},
volume = {68},
pages = {1-12},
year = {2018},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2018.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0923596518303850},
author = {Tinghua Zhang and Kun Gao and Guoqiang Ni and Guihua Fan and Yan Lu},
keywords = {Super resolution, Spatio-temporal, MAP-MRF, SIFT flow},
abstract = {Aiming at improving spatio-temporal resolution of video for real-world applications, this paper focuses on the spatio-temporal super-resolution reconstruction algorithm for multiple asynchronous video sequences. The current multi-video super-resolution algorithms still have some weaknesses in application such as oversimplification of motion, unknown blurring and noise level. For further improvement, a Maximum Posterior Likelihood-Markov Random Field (MAP-MRF) based super-resolution reconstruction method is proposed and proved robust in achieving the real-world super-resolution imaging. The proposed method adopts weighted 3D neighborhood system (WNS) MAP-MRF model to accurately describe the spatial and temporal correlations between multiple video sequences. In order to improve the estimation accuracy of the motions for complex scenes, the improved Scale-Invariant Feature Transform (SIFT) Flow algorithm based on sparsity in wavelet domain is proposed, which can afford the large displacement, rotational movement and other complexities in asynchronous multi-video sequences. The Belief Propagation (BP) algorithm is applied to estimate the parameters of MAP-MRF model, such as motion vector and the super-resolution images in an iterative coarse-to-fine scheme. With the proposed algorithms mentioned above, MAP-MRF based super-resolution reconstruction method has better capabilities of edge sharpness and detailed texture preserving, and robustness of noise suppressing. The experimental result has confirmed the effectiveness of the proposed method under the practical conditions.}
}

@article{zero_shot_2017,
  author       = {Assaf Shocher and
                  Nadav Cohen and
                  Michal Irani},
  title        = {"Zero-Shot" Super-Resolution using Deep Internal Learning},
  journal      = {CoRR},
  volume       = {abs/1712.06087},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.06087},
  eprinttype    = {arXiv},
  eprint       = {1712.06087},
  timestamp    = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-06087.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{kapeller_vsr_cnn_2016,
  author={Kappeler, Armin and Yoo, Seunghwan and Dai, Qiqin and Katsaggelos, Aggelos K.},
  journal={IEEE Transactions on Computational Imaging},
  title={Video Super-Resolution With Convolutional Neural Networks},
  year={2016},
  volume={2},
  number={2},
  pages={109-122},
  doi={10.1109/TCI.2016.2532323}}

@unknown{Yan_frame_vsr_2019,
author = {Yan, Bo and Lin, Chuming and Tan, Weimin},
year = {2019},
month = {09},
pages = {},
title = {Frame and Feature-Context Video Super-Resolution}
}

@article{rbpn_vsr_2019,
  author       = {Muhammad Haris and
                  Greg Shakhnarovich and
                  Norimichi Ukita},
  title        = {Recurrent Back-Projection Network for Video Super-Resolution},
  journal      = {CoRR},
  volume       = {abs/1903.10128},
  year         = {2019},
  url          = {http://arxiv.org/abs/1903.10128},
  eprinttype    = {arXiv},
  eprint       = {1903.10128},
  timestamp    = {Tue, 28 Jun 2022 16:27:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1903-10128.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}







